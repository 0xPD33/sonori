# =============================================================================
# CORE TRANSCRIPTION SETTINGS
# =============================================================================
# These are the most important settings you'll likely want to change

[general_config]
model = "large-v3-turbo"               # Whisper model size (tiny, base, small, medium, large, large-v2, large-v3, large-v3-turbo)
language = "en"                        # Transcription language (use "auto" for auto-detect)
transcription_mode = "manual"          # "realtime" for live transcription, "manual" for push-to-talk

# =============================================================================
# BACKEND CONFIGURATION
# =============================================================================
# Choose the transcription engine and configure its performance

[backend_config]
backend = "whisper_cpp"                # Options: "ctranslate2", "whisper_cpp", "parakeet"
threads = 8                           # Number of CPU threads (default: min(num_cpus, 4))
gpu_enabled = true                    # Enable GPU acceleration (CUDA/Metal/Vulkan)
quantization_level = "medium"         # Precision: "high" (full), "medium" (q8_0), "low" (q5_1)

# =============================================================================
# AUDIO PROCESSING
# =============================================================================
# Configure how audio is captured and processed

[audio_processor_config]
sample_rate = 16000                   # Audio sample rate in Hz (must be 8000 or 16000 for VAD)
buffer_size = 1024                    # Audio buffer size (also used for visualization)

# =============================================================================
# TRANSCRIPTION MODE SETTINGS
# =============================================================================
# Configure real-time and manual transcription modes

[realtime_mode_config]
max_buffer_duration_sec = 30.0        # Maximum audio buffer duration for VAD history (seconds)
max_segment_count = 20                # Maximum number of speech segments to buffer

[manual_mode_config]
max_recording_duration_secs = 120     # Maximum recording time per session (2 minutes)
clear_on_new_session = true           # Clear transcript when starting new session
enable_chunk_overlap = true            # Enable overlap between 30-second chunks (prevents word cutoff)
chunk_overlap_seconds = 0.5            # Overlap duration in seconds (0.5s = industry best practice)
disable_chunking = false               # EXPERIMENTAL: Process entire recording as single segment (no 30s limit)

[vad_config]
threshold = 0.10                      # Speech detection sensitivity (0.0-1.0, lower = more sensitive)
speech_end_threshold = 0.08           # Lower threshold for speech continuation (hysteresis)
hangbefore_frames = 5                 # Frames to wait before confirming speech start (50ms)
hangover_frames = 30                  # Frames to wait after speech ends before cutting (300ms)
silence_tolerance_frames = 8          # Frames of silence to tolerate during speech (80ms)
speech_prob_smoothing = 0.3           # Exponential moving average smoothing factor

[sound_config]
enabled = true                        # Enable sound feedback
volume = 0.5                         # Sound volume (0.0-1.0)

# =============================================================================
# TRANSCRIPTION OPTIONS
# =============================================================================
# Configure transcription behavior

# Common options shared across all backends
[common_transcription_options]
beam_size = 5                         # Beam search width (1 = greedy/fastest, higher = more accurate but slower)
patience = 1.0                        # Beam search patience factor

# CTranslate2-specific options (used when backend = "ctranslate2")
[ctranslate2_options]
repetition_penalty = 1.25             # Penalty for repeated tokens

# Whisper.cpp-specific options (used when backend = "whisper_cpp")
[whisper_cpp_options]
temperature = 0.2                     # Sampling temperature (0.0 = deterministic, higher = more creative)
suppress_blank = true                 # Suppress blank outputs at beginning
no_context = true                     # Disable context to prevent double transcriptions
max_tokens = 0                        # Maximum tokens per segment (0 = auto)
entropy_thold = 2.4                   # Entropy threshold for fallback sampling
logprob_thold = -1.0                  # Log probability threshold for speech detection
no_speech_thold = 0.6                 # No-speech probability threshold

# =============================================================================
# USER INTERFACE & CONTROLS
# =============================================================================
# Configure display and window behavior

[display_config]
vsync_mode = "Enabled"                # VSync: "Auto", "Enabled", "Adaptive", "Disabled", "Mailbox"
target_fps = 60                       # Target FPS when vsync is disabled

[window_behavior_config]
hide_when_idle = true                # Auto-hide window when not recording
auto_hide_delay_ms = 2000             # Delay before auto-hiding (milliseconds)
start_hidden = false                  # Start application with window hidden
show_in_system_tray = true            # Show icon in system tray

# =============================================================================
# SYSTEM INTEGRATION
# =============================================================================
# Configure desktop environment integration and global shortcuts

[portal_config]
enable_xdg_portal = true              # Enable XDG Desktop Portal for input injection
enable_global_shortcuts = true        # Enable global shortcuts via desktop portal
manual_toggle_accelerator = "<Super>backslash"  # Global hotkey for manual mode toggle
application_id = "dev.paddy.sonori"   # Application ID for desktop portal registration
paste_shortcut = "ctrl_shift_v"       # Paste method: "ctrl_shift_v" (terminals) or "ctrl_v" (apps)

# =============================================================================
# TRANSCRIPTION POST-PROCESSING
# =============================================================================
# Clean up transcription artifacts and normalize output

[post_process_config]
enabled = true                        # Enable post-processing of transcriptions
remove_leading_dashes = true          # Remove leading dashes (e.g., "- text" → "text")
remove_trailing_dashes = true         # Remove trailing dashes (e.g., "text -" → "text")
normalize_whitespace = true           # Normalize whitespace (collapse multiple spaces, etc.)

# =============================================================================
# DEBUGGING & DEVELOPMENT
# =============================================================================
# Advanced options for debugging and performance monitoring

[debug_config]
log_stats_enabled = false             # Enable detailed performance logging
save_manual_audio_debug = false        # Save manual mode audio to WAV files for debugging

# =============================================================================
# EXAMPLE CONFIGURATIONS
# =============================================================================
# Uncomment and modify these presets for common use cases:

# Fast, lightweight setup (whisper.cpp + base model):
# backend = "whisper_cpp"
# model = "base.en"
# quantization_level = "medium"  # Downloads ~140MB ggml-base.en-q8_0.bin

# High accuracy setup (CT2 + large model):
# backend = "ctranslate2"
# model = "large-v3"  # Automatically uses distil-whisper/distil-large-v3
# quantization_level = "medium"

# =============================================================================
# MODEL INFORMATION
# =============================================================================
# Available models: tiny, tiny.en, base, base.en, small, small.en, medium, large-v1, large-v2, large-v3
#
# Intelligent mapping for CTranslate2:
#   - tiny, base → openai/whisper-* (standard OpenAI models, already fast)
#   - small, medium, large → distil-whisper/* (distilled models for speed optimization)
#   Examples:
#     "base.en" → "openai/whisper-base.en"
#     "small.en" → "distil-whisper/distil-small.en"
#     "medium" → "distil-whisper/distil-medium.en"
#
# Whisper.cpp always uses standard OpenAI models (e.g., "base.en" → "base.en")
# You can also specify full model paths to bypass mapping: "distil-whisper/distil-small.en"
